@article{apley.zhu.2020.ale,
  author = {Apley, D. W. and Zhu, J.},
  title = {Visualizing the effects of predictor variables in black box supervised learning models},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {82},
  number = {4},
  pages = {1059-1086},
  keywords = {Functional analysis of variance, Marginal plots, Partial dependence plots, Supervised learning, Visualization},
  doi = {10.1111/rssb.12377},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12377},
  eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssb.12377},
  year = {2020}
}

@article{bahn.mcgill.2013,
  author = {V. Bahn and B. J. McGill},
  year = {2013},
  title = {Testing the predictive performance of distribution models},
  journal = {Oikos},
  volume = {122},
  pages = {321-331}
}

@article{bergmeir.benitez.2012,
  author = {C. Bergmeir and J. M. Benitez},
  year = {2012},
  title = {On the use of cross-validation for time series predictor evaluation},
  journal = {Information Sciences},
  volume = {191},
  pages = {192-213}
}

@Manual{bivand.yu.2020.spgwr,
    title = {spgwr: Geographically Weighted Regression},
    author = {R. Bivand and D. Yu},
    year = {2020},
    note = {R package version 0.6-34},
    url = {https://CRAN.R-project.org/package=spgwr},
  }
  
  
@article{breiman.1999.bagging,
  title = {Bagging predictors},
  year = {1999},
  author = {L. Breiman},
  journal = {Machine Learning},
  volme = {24},
  issue = {2},
  pages = {123-140}
}

@article{breiman.2001.randomforest,
  title = {Random Forests},
  year = {2001},
  author = {L. Breiman},
  journal = {Machine Learning},
  volme = {45},
  issue = {1},
  pages = {5-32}
}

@article{brenning2005,
  title = {Spatial Prediction Models for Landslide Hazards: Review, Comparison and Evaluation},
  shorttitle = {Spatial Prediction Models for Landslide Hazards},
  author = {Brenning, A.},
  year = {2005},
  month = nov,
  volume = {5},
  pages = {853--862},
  doi = {10.5194/nhess-5-853-2005},
  journal = {Natural Hazards and Earth System Sciences},
  number = {6}
}

@article{brenning2008,
  title = {Estimating Error Rates in the Classification of Paired Organs},
  author = {Brenning, A. and Lausen, B.},
  year = {2008},
  month = sep,
  volume = {27},
  pages = {4515--4531},
  issn = {0277-6715},
  doi = {10.1002/sim.3310},
  journal = {Statistics in Medicine},
  number = {22}
}


@INPROCEEDINGS{brenning.2012.sperrorest,
  author={A. Brenning},  
  booktitle={2012 IEEE International Geoscience and Remote Sensing Symposium},   
  title={Spatial cross-validation and bootstrap for the assessment of prediction rules in remote sensing: The {R} package sperrorest},
  year={2012},  
  volume={},  
  number={},  
  pages={5372-5375},  
  doi={10.1109/IGARSS.2012.6352393}
}


@article{brenning2015,
  title = {Landslide Susceptibility near Highways Is Increased by 1 Order of Magnitude in the {{Andes}} of Southern {{Ecuador}}, {{Loja}} Province},
  author = {Brenning, A. and Schwinn, M. and {Ruiz-P{\'a}ez}, A. P. and Muenchow, J.},
  year = {2015},
  month = jan,
  volume = {15},
  pages = {45--57},
  doi = {10.5194/nhess-15-45-2015},
  journal = {Natural Hazards and Earth System Sciences},
  number = {1}
}

@article{brenning.2021.wiml,
      title={Transforming Feature Space to Interpret Machine Learning Models},
      author={A. Brenning},
      year={2021},
      pages={2104.04295},
      journal={arXiv},
}

@article{brenning.2021.spdiag.preprint,
      title={Spatial machine-learning model diagnostics: a model-agnostic distance-based approach},
      author={A. Brenning},
      year={2021},
      pages={2111.08478},
      journal={arXiv},
      url = {https://arxiv.org/abs/2111.08478}
}

@article{brenning.2023.spdiag,
      title={Spatial machine-learning model diagnostics: a model-agnostic distance-based approach},
      author={A. Brenning},
      year={2023},
      volume = {37},
      pages={584--606},
      journal={International Journal of Geographical Information Science},
      url = {https://doi.org/10.1080/13658816.2022.2131789}
}

@article{burman1994,
  title = {A Cross-Validatory Method for Dependent Data},
  author = {Burman, P. and Chow, E. and Nolan, D.},
  year = {1994},
  volume = {81},
  pages = {351--358},
  doi = {10.1093/biomet/81.2.351},
  abstract = {SUMMARY: In this paper we extend the technique of cross-validation to the case where observations form a general stationary sequence. We call it h-block cross-validation, because the idea is to reduce the training set by removing the h observations preceding and following the observation in the test set. We propose taking h to be a fixed fraction of the sample size, and we add a term to our h-block cross-validated estimate to compensate for the underuse of the sample. The advantages of the proposed modification over the cross-validation technique are demonstrated via simulation. \textcopyright{} 1994 Biometrika Trust.},
  file = {/Users/pjs/Zotero/storage/IY8F382V/display.html},
  journal = {Biometrika},
  keywords = {cross-validation,Cross-validation,Dependence,Integrated square error,Prediction error,stationary process},
  number = {2}
}

@article{clark.allingham.2011.svgm.ci,
  author = {R. G. Clark and S. Allingham},
  title = {Robust Resampling Confidence Intervals for Empirical Variograms},
  year = {2011},
  journal = {Mathematical Geosciences},
  volume = {43},
  pages = {243-259}
}


@book{cressie.1993,
  title = {Statistics for {{Spatial Data}}},
  author = {Cressie, N. A. C.},
  year = {1993},
  publisher = {{John Wiley \& Sons}},
  doi = {10.1002/9781119115151}
}

@book{cressie.wikle.2011,
  author = {N. A. C. Cressie and C. K. Wikle},
  year = {2011},
  title = {Statistics for Spatio-Temporal Data},
  publisher = {John Wiley \& Sons}
}

@book{desmith.et.al.2007,
  title = {Geospatial Analysis: a Comprehensive Guide to Principles, Techniques and Software Tools},
  author = {M. J. {de Smith} and M. F. Goodchild and P. A. Longley},
  year = {2007},
  publisher = {Troubador},
  address = {Leicester}
}


@article{efron1983,
  title = {A leisurely look at the bootstrap, the jackknife, and cross-validation},
  author = {Efron, B. and Gong, G.},
  year = {1983},
  month = feb,
  volume = {37},
  pages = {36--48},
  doi = {10.1080/00031305.1983.10483087},
  journal = {The American Statistician},
  number = {1}
}

@book{fotheringham.et.al.2002,
  author = {A. S. Fotheringham and C. Brunsdon and M. E. Charlton},
  title = {Geographically weighted regression},
  year = {2002},
  publisher = {Wiley},
  address = {Chichester}
}

@article{fouedjio.2020.rf,
  author = {F. Fouedjio},
  year = {2020},
  title = {Exact Conditioning of Regression Random Forest for Spatial Prediction},
  journal = {Artificial Intelligence in Geosciences},
  volume = {1},
  pages = {11-23}
}

@article{fouedjio.klump.2019,
  author = {F. Fouedjio and J. Klump},
  year = {2020},
  title = {Exploring prediction uncertainty of spatial data in geostatistical and machine learning approaches},
  journal = {Environmental Earth Sciences},
  volume = {78},
  issue = {38},
  pages = {1-24}
}

@article{fox.et.al.2020,
  author = {E. W. Fox and J. M. {Ver Hoef} and A. R. Olsen},
  year = {2020},
  title = {Comparing spatial regression to random forests for large environmental data sets},
  journal = {PLoS ONE},
  volume = {15},
  number = {3},
  pages = {e0229509}
}

@article{friedman.2001.pdp,
  author = {J. Friedman},
  year = {2001},
  title = {Greedy function approximation: a gradient boosting machine},
  journal = {The Annals of Statistics},
  volume = {29},
  number = {5},
  pages = {1189–1232}
}

@article{geiss.2017.ieee,
  title = {On the {{Effect}} of {{Spatially Non}}-{{Disjoint Training}} and {{Test Samples}} on {{Estimated Model Generalization Capabilities}} in {{Supervised Classification With Spatial Features}}},
  author = {Gei{\ss}, C. and {Aravena Pelizari}, P. and Schrade, H. and Brenning, A. and Taubenb{\"o}ck, H.},
  year = {2017},
  volume = {14},
  pages = {2008--2012},
  doi = {10.1109/LGRS.2017.2747222},
  journal = {IEEE Geoscience and Remote Sensing Letters},
  number = {11}
}

@article{goetz.et.al.2015.cg,
  author = {J. N. Goetz and A. Brenning and H. Petschko and P. Leopold},
  year = {2015},
  title = {Evaluating machine learning and statistical prediction techniques for landslide susceptibility modeling},
  journal = {Computers \&{} Geosciences},
  volume = {81},
  pages = {1-11}
}

@article{goovaerts.2000.interpolation,
  author = {P. Goovaerts},
  year = {2000},
  title = {Geostatistical approaches for incorporating elevation into the spatial interpolation of rainfall},
  journal = {Journal of Hydrology},
  volume = {228},
  issue = {1-2},
  pages = {113-129}
}


@Article{graeler.et.al.2016.gstat,
    title = {Spatio-Temporal Interpolation using gstat},
    author = {B. Gräler and E. Pebesma and G. Heuvelink},
    year = {2016},
    journal = {The R Journal},
    volume = {8},
    issue = {1},
    pages = {204-218},
  }

@book{hand1997,
  title = {Construction and {{Assessment}} of {{Classification Rules}}},
  author = {Hand, D. J.},
  year = {1997},
  publisher = {{Wiley}},
  address = {{New York}},
}

@article{hengl.et.al.2004.rk,
  author = {T. Hengl and G. B. M. Heuvelink and A. Stein},
  year = {2004},
  title = {A generic framework for spatial prediction of soil variables based on regression-kriging},
  journal = {Geoderma},
  volume = {120},
  pages = {75-93}
}

@article{hengl.et.al.2015.rfrk,
  author = {T. Hengl and G. B. M. Heuvelink and B. Kempen and J. G. B. Leenaars and M. G. Walsh and K. D. Shepherd and A. Sila and R. A. MacMillan and J. {Mendes de Jesus} and L. Tamene and J. E. Tondoh},
  year = {2015},
  title = {Mapping Soil Properties of Africa at 250 m Resolution: Random Forests Significantly Improve Current Predictions},
  journal = {PLoS ONE},
  volume = {10},
  issue = {6},
  pages = {e0125814}
}

@article{hothorn.lausen.2005.bundling,
  title = {Bundling classifiers by bagging trees},
  year = {2005},
  author = {T. Hothorn and B. Lausen},
  journal = {Computational Statistics \&{} Data Analysis},
  volume = {49},
  pages = {1068-1078}
}

@book{isaaks.srivastava.1989,
  author = {E. H. Isaaks and R. M. Srivastava},
  title = {Applied Geostatistics},
  year = {1989},
  publisher = {Oxford University Press},
  address = {New York}
}

@article{karasiak2021,
  title = {Spatial Dependence between Training and Test Sets: Another Pitfall of Classification Accuracy Assessment in Remote Sensing},
  author = {Karasiak, N. and Dejoux, J.-F. and Monteil, C. and Sheeren, D.},
  year = {2021},
  month = apr,
  issn = {1573-0565},
  doi = {10.1007/s10994-021-05972-1},
  abstract = {Spatial autocorrelation is inherent to remotely sensed data. Nearby pixels are more similar than distant ones. This property can help to improve the classification performance, by adding spatial or contextual features into the model. However, it can also lead to overestimation of generalisation capabilities, if the spatial dependence between training and test sets is ignored. In this paper, we review existing approaches that deal with spatial autocorrelation for image classification in remote sensing and demonstrate the importance of bias in accuracy metrics when spatial independence between the training and test sets is not respected. We compare three spatial and non-spatial cross-validation strategies at pixel and object levels and study how performances vary at different sample sizes. Experiments based on Sentinel-2 data for mapping two simple forest classes show that spatial leave-one-out cross-validation is the better strategy to provide unbiased estimates of predictive error. Its performance metrics are consistent with the real quality of the resulting map contrary to traditional non-spatial cross-validation that overestimates accuracy. This highlight the need to change practices in classification accuracy assessment. To encourage it we developped Museo ToolBox, an open-source python library that makes spatial cross-validation possible.},
  journal = {Machine Learning}
}


@article{hooker.mentch.2019.stop,
      title={Please stop permuting features: an explanation and alternatives}, 
      author={G. Hooker and L. Mentch},
      year={2019},
      pages={1905.03151},
      journal={arXiv preprint},
}


@Article{liaw.wiener.2002.randomforest,
    title = {Classification and Regression by randomForest},
    author = {A. Liaw and M. Wiener},
    journal = {R News},
    year = {2002},
    volume = {2},
    number = {3},
    pages = {18-22},
  }
  
  
@article{meyer2018,
  title = {Improving Performance of Spatio-Temporal Machine Learning Models Using Forward Feature Selection and Target-Oriented Validation},
  author = {Meyer, H. and Reudenbach, C. and Hengl, T. and Katurji, M. and Nauss, T.},
  year = {2018},
  volume = {101},
  pages = {1--9},
  doi = {10.1016/j.envsoft.2017.12.001},
  journal = {Environmental Modelling \& Software},
}


@Article{molnar.et.al.2018.iml,
    author = {C. Molnar and B. Bischl and G. Casalicchio},
    title = {iml: an {R} package for interpretable machine learning},
    doi = {10.21105/joss.00786},
    url = {https://joss.theoj.org/papers/10.21105/joss.00786},
    year = {2018},
    publisher = {Journal of Open Source Software},
    volume = {3},
    number = {26},
    pages = {786},
    journal = {JOSS},
}

@book{molnar.2019.iml.book,
  title      = {Interpretable machine learning},
  author     = {C. Molnar},
  note       = {\url{https://christophm.github.io/interpretable-ml-book/}},
  year       = {2019},
  subtitle   = {A guide for making black box models explainable},
  url = {https://christophm.github.io/interpretable-ml-book/}
}

@misc{molnar.et.al.2020.review,
      title={Interpretable machine learning -- a brief history, state-of-the-art and challenges}, 
      author={C. Molnar and G. Casalicchio and B. Bischl},
      year={2020},
      eprint={2010.09337},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{molnar.et.al.2020.pitfalls,
      title={Pitfalls to avoid when interpreting machine learning models}, 
      author={C. Molnar and G. König and J. Herbinger and T. Freiesleben and S. Dandl and C. A. Scholbeck and G. Casalicchio and M. Grosse-Wentrup and B. Bischl},
      year={2020},
      eprint={2007.04131},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{molnar.et.al.2020.conditional,
      title={Model-agnostic feature importance and effects with dependent features -- a conditional subgroup approach}, 
      author={C. Molnar and G. König and B. Bischl and G. Casalicchio},
      year={2020},
      eprint={2006.04628},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{murdoch.et.al.2019.iml,
  author = {W. J. Murdoch and C. Singh and K. Kumbier and R. Abbasi-Asl and B. Yu},
  	title = {Definitions, methods, and applications in interpretable machine learning},
	volume = {116},
	number = {44},
	pages = {22071--22080},
	year = {2019},
	doi = {10.1073/pnas.1900654116},
	URL = {https://www.pnas.org/content/116/44/22071},
	journal = {Proceedings of the National Academy of Sciences}
}

@article{olea.2011.svgm.ci,
  author = {R. Olea and E. Pardo-Iguzquiza},
  year = {2011},
  title = {Generalized Bootstrap Method for Assessment of Uncertainty in Semivariogram Inference},
  journal = {Mathematical Geosciences},
  volume = {43},
  pages = {203-228}
}

@article{pal.2005,
  author = {M. Pal},
  title = {Random forest classifier for remote sensing classification},
  year = {2005},
  journal = {International Journal of Remote Sensing},
  volume = {26},
  number = {1},
  pages = {217-222}
}

@book{palmer.hagedorn.2006,
  author = {T. Palmer and R. Hagedorn},
  year = {2006},
  title = {Predictability of Weather and Climate},
  publisher = {Cambridge University Press}
}

@article{pebesma.bivand.2005.sp,
    author = {E. J. Pebesma and R. S. Bivand},
    title = {Classes and methods for spatial data in {R}},
    journal = {R News},
    year = {2005},
    volume = {5},
    number = {2},
    pages = {9--13},
  }

@article{pena.brenning.2015.maipo,
  author = {M. A. Peña and A. Brenning},
  title = {Assessing fruit-tree crop classification from {Landsat}-8 time series for the {Maipo} valley, {Chile}},
  journal = {Remote Sensing of Environment},
  volume = {171},
  pages = {234-244},
  year = {2015},
  doi = {10.1016/j.rse.2015.10.029},
}

@article{pena.et.al.2017.spectrotemporal,
  author = {M. A. Peña and R. Liao and A. Brenning},
  title = {Using spectrotemporal indices to improve the fruit-tree crop classification accuracy},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume = {128},
  pages = {158-169},
  year = {2017},
  issn = {0924-2716},
  doi = {10.1016/j.isprsjprs.2017.03.019},
  url = {https://www.sciencedirect.com/science/article/pii/S0924271616305019},
}

@Manual{peters.hothorn.2021.ipred,
    title = {{ipred}: Improved Predictors},
    author = {A. Peters and T. Hothorn},
    year = {2021},
    note = {R package version 0.9-11},
    url = {https://CRAN.R-project.org/package=ipred},
}
  
@article{pohjankukka2017,
  title = {Estimating the Prediction Performance of Spatial Models via Spatial K-Fold Cross Validation},
  author = {Pohjankukka, J. and Pahikkala, T. and Nevalainen, P. and Heikkonen, J.},
  year = {2017},
  volume = {31},
  pages = {2001--2019},
  doi = {10.1080/13658816.2017.1346255},
  journal = {International Journal of Geographical Information Science},
  number = {10}
}

@article{rest2014,
  title = {Spatial Leave-One-out Cross-Validation for Variable Selection in the Presence of Spatial Autocorrelation},
  author = {{Le Rest}, K. and Pinaud, D. and Monestiez, P. and Chadoeuf, J. and Bretagnolle, V.},
  year = {2014},
  volume = {23},
  pages = {811--820},
  issn = {1466-8238},
  doi = {10.1111/geb.12161},
  abstract = {Aim Processes and variables measured in ecology are almost always spatially autocorrelated, potentially leading to the choice of overly complex models when performing variable selection. One way to solve this problem is to account for residual spatial autocorrelation (RSA) for each subset of variables considered and then use a classical model selection criterion such as the Akaike information criterion (AIC). However, this method can be laborious and it raises other concerns such as which spatial model to use or how to compare different spatial models. To improve the accuracy of variable selection in ecology, this study evaluates an alternative method based on a spatial cross-validation procedure. Such a procedure is usually used for model evaluation but can also provide interesting outcomes for variable selection in the presence of spatial autocorrelation. Innovation We propose to use a special case of spatial cross-validation, spatial leave-one-out (SLOO), giving a criterion equivalent to the AIC in the absence of spatial autocorrelation. SLOO only computes non-spatial models and uses a threshold distance (equal to the range of RSA) to keep each point left out spatially independent from the others. We first provide some simulations to evaluate how SLOO performs compared with AIC. We then assess the robustness of SLOO on a large-scale dataset. R software codes are provided for generalized linear models. Main conclusions The AIC was relevant for variable selection in the presence of RSA if the independent variables considered were not spatially autocorrelated. It otherwise failed because highly spatially autocorrelated variables were more often selected than others. Conversely, SLOO had similar performances whether the variables were themselves spatially autocorrelated or not. It was particularly useful when the range of RSA was small, which is a common property of spatial tools. SLOO appears to be a promising solution for selecting relevant variables from most ecological spatial datasets.},
  doi = {10.1111/geb.12161},
  journal = {Global Ecology and Biogeography},
  number = {7}
}

@article{roberts2017,
  title = {Cross-Validation Strategies for Data with Temporal, Spatial, Hierarchical, or Phylogenetic Structure},
  author = {Roberts, D. R. and Bahn, V. and Ciuti, S. and Boyce, M. S. and Elith, J. and {Guillera-Arroita}, G. and Hauenstein, S. and {Lahoz-Monfort}, J. J. and Schr{\"o}der, B. and Thuiller, W. and Warton, D. I. and Wintle, B. A. and Hartig, F. and Dormann, C. F.},
  year = {2017},
  volume = {40},
  pages = {913--929},
  publisher = {{Wiley}},
  doi = {10.1111/ecog.02881},
  journal = {Ecography},
  number = {8}
}


@inproceedings{russ.brenning.2010,
  title = {Data Mining in Precision Agriculture: Management of Spatial Information},
  shorttitle = {Data Mining in Precision Agriculture},
  booktitle = {Computational {{Intelligence}} for {{Knowledge}}-{{Based Systems Design}}},
  author = {Ru{\ss}, G. and Brenning, A.},
  editor = {H{\"u}llermeier, E. and Kruse, R. and Hoffmann, F.},
  year = {2010},
  pages = {350--359},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-14049-5_36},
  abstract = {Precision Agriculture is the application of state-of-the-art GPS technology in connection with site-specific, sensor-based treatment of the crop. It can also be described as a data-driven approach to agriculture, which is strongly connected with a number of data mining problems. One of those is also an inherently important task in agriculture: yield prediction. The question is: can a field's yield be predicted in-season using available geo-coded data sets?In the past, a number of approaches have been proposed towards this problem. Often, a broad variety of regression models for non-spatial data have been used, like regression trees, neural networks and support vector machines. But in a cross-validation learning approach, issues with the assumption of the data records' statistical independence keep emerging. Hence, the geographical location of data records should clearly be considered while establishing a regression model and assessing its predictive performance. This paper gives a short overview of the available data, points out in detail the main issue with the classical learning approaches and presents a novel spatial cross-validation technique to overcome the problems with the classical approach towards the aforementioned yield prediction task.},
  file = {/Users/pjs/Zotero/storage/TMEC3JG7/Ruß und Brenning - 2010 - Data Mining in Precision Agriculture Management o.pdf},
  isbn = {978-3-642-14049-5},
  keywords = {Precision Agriculture,Regression,Spatial Cross-Validation,Spatial Data Mining},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@InProceedings{russ.brenning.2010.svi,
author="Ru{\ss}, G. and Brenning, A.",
editor="Cohen, P. R. and Adams, N. M. and Berthold, M. R.",
title="Spatial Variable Importance Assessment for Yield Prediction in Precision Agriculture",
booktitle="Advances in Intelligent Data Analysis IX",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="184-195",
abstract="Precision Agriculture applies state-of-the-art GPS technology in connection with site-specific, sensor-based crop management. It can also be described as a data-driven approach to agriculture, which is strongly connected with a number of data mining problems. One of those is also an inherently important task in agriculture: yield prediction. Given a yield prediction model, which of the predictor variables are the important ones?"
}



@article{schratz2019,
  title = {Hyperparameter Tuning and Performance Assessment of Statistical and Machine-Learning Algorithms Using Spatial Data},
  author = {Schratz, P. and Muenchow, J. and Iturritxa, E. and Richter, J. and Brenning, A.},
  year = {2019},
  volume = {406},
  pages = {109--120},
  doi = {10.1016/j.ecolmodel.2019.06.002},
  journal = {Ecological Modelling}
}

@article{schratz2021,
      title={Mlr3spatiotempcv: Spatiotemporal resampling methods for machine learning in {R}},
      author={Patrick Schratz and Marc Becker and Michel Lang and Alexander Brenning},
      year={2021},
      pages={2110.12674},
      journal={arXiv},
}

@article{sekulic.et.al.2020,
  title = {Random Forest Spatial Interpolation},
  author = {Sekuli{\'c}, A. and Kilibarda, M. and Heuvelink, G. B. M. and Nikoli{\'c}, M. and Bajat, B.},
  year = {2020},
  volume = {12},
  pages = {1687},
  doi = {10.3390/rs12101687},
  abstract = {For many decades, kriging and deterministic interpolation techniques, such as inverse distance weighting and nearest neighbour interpolation, have been the most popular spatial interpolation techniques. Kriging with external drift and regression kriging have become basic techniques that benefit both from spatial autocorrelation and covariate information. More recently, machine learning techniques, such as random forest and gradient boosting, have become increasingly popular and are now often used for spatial interpolation. Some attempts have been made to explicitly take the spatial component into account in machine learning, but so far, none of these approaches have taken the natural route of incorporating the nearest observations and their distances to the prediction location as covariates. In this research, we explored the value of including observations at the nearest locations and their distances from the prediction location by introducing Random Forest Spatial Interpolation (RFSI). We compared RFSI with deterministic interpolation methods, ordinary kriging, regression kriging, Random Forest and Random Forest for spatial prediction (RFsp) in three case studies. The first case study made use of synthetic data, i.e., simulations from normally distributed stationary random fields with a known semivariogram, for which ordinary kriging is known to be optimal. The second and third case studies evaluated the performance of the various interpolation methods using daily precipitation data for the 2016\&ndash;2018 period in Catalonia, Spain, and mean daily temperature for the year 2008 in Croatia. Results of the synthetic case study showed that RFSI outperformed most simple deterministic interpolation techniques and had similar performance as inverse distance weighting and RFsp. As expected, kriging was the most accurate technique in the synthetic case study. In the precipitation and temperature case studies, RFSI mostly outperformed regression kriging, inverse distance weighting, random forest, and RFsp. Moreover, RFSI was substantially faster than RFsp, particularly when the training dataset was large and high-resolution prediction maps were made.},
  journal = {Remote Sensing},
  language = {en},
  number = {10}
}

@article{sekulic2021,
  title = {A High-Resolution Daily Gridded Meteorological Dataset for {{Serbia}} Made by {{Random Forest Spatial Interpolation}}},
  author = {Sekuli{\'c}, A. and Kilibarda, M. and Proti{\'c}, D. and Bajat, B.},
  year = {2021},
  volume = {8},
  pages = {123},
  doi = {10.1038/s41597-021-00901-2},
  abstract = {We produced the first daily gridded meteorological dataset at a 1-km spatial resolution across Serbia for 2000\textendash 2019, named MeteoSerbia1km. The dataset consists of five daily variables: maximum, minimum and mean temperature, mean sea-level pressure, and total precipitation. In addition to daily summaries, we produced monthly and annual summaries, and daily, monthly, and annual long-term means. Daily gridded data were interpolated using the Random Forest Spatial Interpolation methodology, based on using the nearest observations and distances to them as spatial covariates, together with environmental covariates to make a random forest model. The accuracy of the MeteoSerbia1km daily dataset was assessed using nested 5-fold leave-location-out cross-validation. All temperature variables and sea-level pressure showed high accuracy, although accuracy was lower for total precipitation, due to the discontinuity in its spatial distribution. MeteoSerbia1km was also compared with the E-OBS dataset with a coarser resolution: both datasets showed similar coarse-scale patterns for all daily meteorological variables, except for total precipitation. As a result of its high resolution, MeteoSerbia1km is suitable for further environmental analyses.},
  journal = {Scientific Data},
  number = {1}
}


@Article{skoien.et.al.2006,
AUTHOR = {Sk{\o}ien, J. O. and Merz, R. and Bl\"oschl, G.},
TITLE = {Top-kriging - geostatistics on stream networks},
JOURNAL = {Hydrology and Earth System Sciences},
VOLUME = {10},
YEAR = {2006},
NUMBER = {2},
PAGES = {277--287},
DOI = {10.5194/hess-10-277-2006}
}


@article{strobl.et.al.2008.conditional,
  author = {C. Strobl and A.-L. Boulesteix and T. Kneib and T. Augustin and A. Zeileis}, 
  year = {2008},
  title = {Conditional variable importance for random forests},
  journal = {BMC Bioinformatics},
  volume = {9},
  number = {1},
  pages = {307}, 
  doi = {10.1186/1471-2105-9-307},
}

@article{valavi2019,
  title = {{{blockCV}}: {{An R}} Package for Generating Spatially or Environmentally Separated Folds for k-Fold Cross-Validation of Species Distribution Models},
  author = {Valavi, R. and Elith, J. and {Lahoz-Monfort}, J. J. and {Guillera-Arroita}, G.},
  year = {2019},
  volume = {10},
  pages = {225--232},
  doi = {10.1111/2041-210X.13107},
  journal = {Methods in Ecology and Evolution},
  number = {2}
}

@Book{venables.ripley.2002,
    title = {Modern {A}pplied {S}tatistics with {S}},
    author = {W. N. Venables and B. D. Ripley},
    publisher = {Springer},
    edition = {Fourth},
    address = {New York},
    year = {2002},
  }
  
@article{veronesi.schillaci.2019,
  author = {F. Veronesi and C. Schillaci},
  year = {2019},
  title = {Comparison between geostatistical and machine learning models as predictors of topsoil organic carbon with a focus on local uncertainty estimation},
  journal = {Ecological Indicators},
  volume = {101},
  pages = {1032-1044}
}

@book{webster.oliver.2007,
  title = {Geostatistcs for {Environmental} {Scientists}},
  author = {R. Webster and M. A. Oliver},
  year = {2007},
  publisher = {{John Wiley \& Sons, Inc.}},
  address = {Chichester}
}

@Book{wood.2017.gam,
    title = {Generalized Additive Models: An Introduction with R},
    year = {2017},
    author = {S.N Wood},
    edition = {2},
    publisher = {Chapman and Hall/CRC},
  }
